{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b2fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d5b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://books.toscrape.com/catalogue/category/books_1/index.html\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9184ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92818478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../books/travel_2/index.html', '../books/mystery_3/index.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all <a> tags within the specified <div>\n",
    "links = soup.find('div', class_='side_categories').find_all('a')\n",
    "\n",
    "# Extract the href attributes from the <a> tags\n",
    "links_list = [link.get('href') for link in links]\n",
    "links_list = links_list[1:-1]\n",
    "\n",
    "links_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1caf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/category/books/travel_2/index.html',\n",
       " 'http://books.toscrape.com/catalogue/category/books/mystery_3/index.html']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_categories_links_list = []\n",
    "\n",
    "for link in links_list:\n",
    "    # Replace the initial part of the URL\n",
    "    new_link = link.replace('../', 'http://books.toscrape.com/catalogue/category/')\n",
    "    # Append the modified link to the new list\n",
    "    books_categories_links_list.append(new_link)\n",
    "    \n",
    "books_categories_links_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3659ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['travel', 'mystery', 'historical-fiction', 'sequential-art', 'classics', 'philosophy', 'romance', 'womens-fiction', 'fiction', 'childrens', 'religion', 'nonfiction', 'music', 'default', 'science-fiction', 'sports-and-games', 'add-a-comment', 'fantasy', 'new-adult', 'young-adult', 'science', 'poetry', 'paranormal', 'art', 'psychology', 'autobiography', 'parenting', 'adult-fiction', 'humor', 'horror', 'history', 'food-and-drink', 'christian-fiction', 'business', 'biography', 'thriller', 'contemporary', 'spirituality', 'academic', 'self-help', 'historical', 'christian', 'suspense', 'short-stories', 'novels', 'health', 'politics', 'cultural', 'erotica']\n"
     ]
    }
   ],
   "source": [
    "books_names_lst = []\n",
    "\n",
    "for url in books_categories_links_list:\n",
    "    books_names_lst.append(url.split('http://books.toscrape.com/catalogue/category/books/')[1].split('_')[0])\n",
    "    \n",
    "print(books_names_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b105c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_titles(soup):\n",
    "    books_titles = soup.find_all('h3')\n",
    "    books_titles_lst = []\n",
    "\n",
    "    for book_title in books_titles:\n",
    "        book_title = book_title.find('a').attrs['title']\n",
    "        books_titles_lst.append(book_title)\n",
    "    \n",
    "    return books_titles_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdc885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_prices(soup):\n",
    "    prices = soup.find_all('p', attrs={\"class\": \"price_color\"})\n",
    "    price_lst = []\n",
    "\n",
    "    for price in prices:\n",
    "        price = price.get_text()\n",
    "        price = float(price.replace('Â£', ''))\n",
    "        price_lst.append(price)\n",
    "    \n",
    "    return price_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ba4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_ratings(soup):\n",
    "    books_rating = soup.find_all('p', attrs={\"class\": 'star-rating'})\n",
    "    books_rating_lst = []\n",
    "    books_rating_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "\n",
    "    for book_rating in books_rating:\n",
    "        book_rating = book_rating.attrs['class'][1]\n",
    "        book_rating = books_rating_dict[book_rating]\n",
    "        books_rating_lst.append(book_rating)\n",
    "    \n",
    "    return books_rating_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b097b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r\"G:\\books scraping\\categories\\Books Scraping.csv\"\n",
    "\n",
    "# Write the CSV header only once before the loop\n",
    "with open(csv_file, 'w', encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Title', 'Price', 'Rate', 'Category'])\n",
    "    writer.writeheader()\n",
    "\n",
    "# Iterate over each URL and name simultaneously\n",
    "for url, name in zip(books_categories_links_list, books_names_lst):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    books_titles_lst = get_books_titles(soup)\n",
    "    price_lst = get_books_prices(soup)\n",
    "    books_rating_lst = get_books_ratings(soup)\n",
    "    \n",
    "    # Append data to the CSV file inside the loop\n",
    "    with open(csv_file, 'a', encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['Title', 'Price', 'Rate', 'Category'])\n",
    "\n",
    "        for book_title, price, rate in zip(books_titles_lst, price_lst, books_rating_lst):\n",
    "            writer.writerow({\"Title\": book_title, 'Price': price, 'Rate': rate, 'Category': name})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
